{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short path, Reconstructing the path\n",
    "In this assignment you will use Spark to compute the shortest path between two vertices. In the video, you have learned how to compute the distances between a source vertex and all other vertices in a graph. Now, your task is to reconstruct the shortest path, that is a sequence of vertices connected by the edges.\n",
    "\n",
    "Dataset location: /data/twitter/twitter_sample_small.txt\n",
    "\n",
    "Format: user_id \\t follower_id\n",
    "\n",
    "You can start with the code described in \"Starter...\" (see the next self-reading).\n",
    "\n",
    "Your task is to find the shortest path between vertices 12 and 34. In case of multiple shortest paths (that is, disjoint paths with the same length), any will suffice. Output format is the sequence of vertices, delimited by a comma, without spaces. For example, the path “12 -> 42 -> 34” should be printed as:\n",
    "    \n",
    "12,42,34\n",
    "\n",
    "Hint: before submitting, check your stopping criteria. In BFS, the search was exhaustive, and in this task your program may terminate earlier, thus saving some precious time.\n",
    "\n",
    "The result on the sample dataset:\n",
    "    \n",
    "12,422,53,52,107,20,23,274,34\n",
    "\n",
    "If you want to deploy the environment on your own machine, please use bigdatateam/all-spark-with-data Docker container. New image: bigdatateam/hysh-full:py3-c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local\").set(\"spark.cores.max\", \"16\"))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAddress = \"/data/twitter/twitter_sample_small.txt\"\n",
    "n = 10  \n",
    "start, end = 12, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_edge(s):\n",
    "    user, follower = s.split(\"\\t\")\n",
    "    return (int(follower), int(user))\n",
    "\n",
    "def step(item):\n",
    "    prev_v, prev_d, next_v = item[0], item[1][0], item[1][1]\n",
    "    return (next_v, prev_d + [next_v])\n",
    "\n",
    "def found():\n",
    "    return  paths.filter(lambda x: x[0] == end).count()\n",
    "\n",
    "forward_edges = sc.textFile(dataAddress).map(parse_edge).cache().partitionBy(n).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,422,53,52,107,20,23,274,34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "paths = sc.parallelize([(start, [start])]).partitionBy(n)\n",
    "\n",
    "\n",
    "while not found():\n",
    "    paths = paths.join(forward_edges, n).map(step).cache()\n",
    "\n",
    "final_paths = (paths.filter(lambda value: value[0] == end)\n",
    "                    .map(lambda value: value[1])\n",
    "                   ).cache()\n",
    "\n",
    "result = final_paths.take(1)[0]\n",
    "\n",
    "print(','.join(map(str,result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
